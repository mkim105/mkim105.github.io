---
title: "Supervised Learning & (Multiple) Linear Regression"
date: 2019-09-12 12:00:00 -0400
categories: DataAnalytics
---
# Week05_01&02 ~ Week07_02

## Supervised Learning; 지도학습
*Supervised Learning VS Unsupervised Learning*
  + 이미 정의되있거나 알려진 데이터를 가지고 unknown data를 추론하는 학습 -> **예측 모델을 만드는 학습**
    + We have the truth/knowledge
      + numerical variable -> Regression models 사용
      + nominal variable -> Classification models 사용
    + We learn from training data to validate on test set
    + We have metrics to evaluate the models; 모델을 평가하기위한 측정방법이 존재한다.
  + Unsupervised Learning(비지도학습, 자율학습)은 unlabelled data로 부터 패턴을 추적하는 학습
    + We do **not** have the truth/knowledge
    + It is used to discover unknown structure or patterns
    + There are no metrics to evaluate the results; 결과를 평가하기 위한 측정방법이 존재하지 않는다. 
  
  + Example
    + undergraduate, graduate, PhD 학생이 인천대학교에 있다. 학생들의 나이, 성별, 주소, 학부 등이 주어졌을 때 사람들의 undergraduate/graduate/PhD 여부를 구분하고 싶다.
      * > Supervised Learning : We already pre differentiate those groups.
    + 소비자의 쇼핑 패턴을 발견하기 위해 소비자 구매 행동을 조사하고 싶다. 예를 들어, 우유를 산 사람은 빵을 같이 살 확률이 높다.
      * > Unsupervised Learning : each transaction에서 우리는 receipt(data)를 보고 패턴을 파악해야함.

*Standard Process In Supervised Learning*

*Data Splits for Evaluations; 모델 평가를 위한 데이터 분리*
  1. Hold-out Evaluation 
    + 데이터가 충분히 클 때 쓴다.(Usually when a data set has more than million rows, it considers as large!)
    + Training Data Set은 Testing Data Set보다 항상 커야 한다.
    + 위의 조건을 만족하면 Training Data Set/Testing Data Set의 비율은 상관이 없다.<br>보통은 80:20으로 하는 듯
    + Training을 위한 데이터는 randomly하게 선택되어야 한다.<br>**Do not forget to shuffle the data!!**
    + Training Data Set/Validation Data Set/Unseen Data Set 나눠서 각 역할에 맞게 수행.
    + **모델을 만들 때 lm()으로 만든다.**
    + **Test Data Set으로 predicted value를 만들 때는 predict.glm()을 쓴다.
    + **prediction error RMSE는 위 두 모델을 이용한다. W6-01-45p 참조**
    
  2. N-folds Cross Evaluation
    + 데이터가 상대적으로 작을 때 쓴다.(Usually when a data set has less than million rows, it considers as small!)
    + 전체 데이터를 기준으로 라운드를 정하고,(Usually we choose N(데이터를 부분내는 수) as 5 or 10)<br>각 라운드 마다 각 부분이 Training Set/Validation Set이 되어서 Evaluation을 진행한다.
    + Final Accuracy = Average(Round 1, Round 2, ...)
    + N-folds Cross Evaluation을 이용하기 위해서는 모델을 먼저 만들어야한다.
    + N-folds Cross Evaluation을 이용한다면 굳이 Training Set/Validation Set을 나눌 필요가 없다.
    + In linear regression, you need to use feature selections to figure out a list of possible models. 
    + **모델을 만들 때 glm()으로 만든다.**
    + **모델을 평가할 때 cv.glm()으로 MSE, Adj-MSE를 본다.**
  3. 일반적인 오해
    + 모델의 정확도를 올리기 위해 두 방법 모두를 썼을 때, Hold-out evaluation의 정확도가 높게 나와서 이 모델이 더 낫다고 생각.
      + 데이터 세트마다 어떤 방법을 쓰냐에 따라서 정확도가 달라짐. 더 나은 모델이라는 것은 없음.

*Predictive Models*
  + Evaluation Metrics 모델평가 측정방법
    + Linear Regression -> the variable to be predicted is numerical 
      * -> **Use error-based metrics; 에러 측정**
    + Classification -> the variables to be predicted is categorical 
      * -> **Use accuracy-based metrics; 정확도 측정** 

## Predictive Models; 예측모델
  + 예측 모델을 만드는 것은 outcome을 에측하기 위한 관련 기술을 사용하는 과정이라고 할 수 있다.(e.g., 통계학, 데이터 마이닝, 머신러닝)
  + 각각의 모델들은 결과에 영향을 미칠 수 있는 predictors, factors로 이루어져 있다.
  + 다양한 예측 변수를 이용하여 예측을 위한 내부 패턴을 얻어 낼 수 있다.

## Regression Analysis; 회귀분석
+ 회귀선에서는 예측값과 관측값 사이의 vertical distance를 줄이는 것이 목표이다.
  + 예측모델의 정확도는 관측값이 회귀선으로부터 얼마나 spread out 되어 있냐에 달려있다.

*The types of linear regression; 선형회귀의 종류*
  * Simple Linear Regression; 단순선형회귀
    + y 1개, x 1개
  * Multiple Linear Regression; 다중선형회귀
    + y 1개, x 여러 개
  * Multivariate Linear Regression; 다변량선형회귀
    + y 여러 개, x 여러 개

*Linear relationship이 나타나지 않으면 어떻게 하지?*
  + x와 y 간에 linear relations나 not clear linear relations가 나타나면 어떻게 해야할까?
  + 솔루션
    + x, y에 transformation을 해본다. 보통, x를 먼저 해보고 그 다음 y를 해본다.
    + 만약에 transformation이 통하지 않는다면 x를 무시할 필요가 있다.
      + 하지만 polynomial regression(다항회귀)나 non-linear analytics models도 고려해볼 필요가 있다.
      
*x와 y가 linear relationship을 가진다는 것을 어떻게 결정하지?*
  1. scatter plot의 개형을 확인한다. 개형에서 정확히 파악할 수 없으면 2.를 따른다.
  2. correlation coefficent를 확인한다.
    + [-0.4, 0.4] : Weak linear relationship
    + [-0.1, 0.1] : Almost no linear relationship 
    
## Build Models
*Feature Selection*
  + 선형회귀라는 테크닉 안에서 우리는 다른 모델을 만들 수 있다.<br>이러한 모델을 만드는 하나의 방법이 **feature selection**이다.
  + Feature Selection이란 **회귀모델을 만드는데 있어서 useful한 x variables를 골라내는 작업이다.**
  + 왜 Feature selection이 필요한가?
    1. 모든 x variables/feature가 useful하지는 않다.
    2. 다른 x varaibles를 이용하여 다른 모델들을 만들어 낼 수  있다.
    3. 만들어진 다른 모델들은 다른 퍼포먼스를 갖는다.
  + Feature Selection은 데이터 마이닝의 일반적인 프로세스이기도 하다.<br>이것은 또한 항상 두 가지 요소를 가진다.<br>이 게시글에서는 선형회귀만을 위한 Feature Selection만을 다룬다.
    1. The best model을 정의하기 위한 기준
      + Individual parameter test에서의 p-value
        + Indicate x variable is useful or not 
      + Akaike/Bayes Information Criterion (AIC/BIC) 값
        + 우리는 AIC/BIC를 최소화하기를 원한다.
      + coefficient of determination adj-R2의 최적화
        + 우리는 Adj-R2를 최대화하기를 원한다. 하지만 거기에는 Overfitting problem이 발생할 수 있다.
      + Mallows's Cp Statistics의 최적화
      + PRESS statistics(errors와 유사한 측정방법)의 최소화
    2. The search or rank methods
      *Search algorithms - K independent varaibles*
      + Backward elimination
        + full model로 시작해서 reasonable한 모델을 찾을 때 까지 x variable을 하나씩 제거해 나가는 방법.<br>보통 Goodness of fit(F-test)를 이용한다.
        + Two methods in backward elimination
          1. by using p-value as metric
            Individual Parameter Test에서 p값이 가장 큰 x variable을 수동으로 하나씩 지워나간다.
            + 그런데 왜 하나씩 지워나가지?
              + x variables간에 correlation이 있을 수 있어서 그것을 고려하여 지워나가는 것임.
          2. by using AIC/BIC metric
            + R이 자동으로 프로세스를 진행해서 마지막에는 최소화된 AIC/BIC 값을 줄 것 이다.
            + 컴퓨터가 자동으로 값을 도출해냈기에, x variable들의 t검정 값이 p > α 이어도 **해당 x variable은 제거하지 않는다.**
      + Forward selection
        + empty model로 시작해서 x variable을 하나씩 추가해 나가며 마지막에는 best model을 선택한다.
      + Best subset regression
        + Computer가 best regression equations with 1, 2, 3,...k-1 idependent x variables 리스트를 보여준다.
        + 각 스텝(예를 들어 model with highest R2-adj, or lowest PRESS statistics)에서 best model들을 추출한다.<br>추출 method는 선택할 수 있다.
        + 더 이상 모델의 향상이 없을 때 중단한다.
      + Stepwise regression
        + Backward elimination과 forward selection의 combination이다. 
      
      *모델 선택에 있어서 중요점*
      + 모델을 선택함에 다른 모델들보다 굉장히 유니크하거나 옵티멀한 모델은 존재하지 않는다.
      + 다른 search algorithm들은 다른 결과를 줄 수 있다.
        + 항상 선택된 모델이 적절한지, 가정은 충족되었는지에 대해 진단해야 한다.
    
## Other steps
  + Goodness of Fit Test; 적합도검정
    + 관찰 결과가 이론에 잘 맞는 정도
      * 모델을 만들었다면, 모델이 qualified 되었는지 안되었는지를 검정해야한다.
        * How to determine a model is qualified? (아래 두 개 모두 통과해야한다.)
          1. F검정 통과
          2. Residual Analysis의 요구조건을 충족
      * 모델이 qualified 되지 않았다면 문제를 찾고, fix it and re-build the model. 
      
    + 적합도검정에는 여러 검정방법이 있고 regression model에 대해서는 F검정을 쓴다. 
    + F검정은 **모든** x variable들이 useful한지, 어떤 x variable들이 influential한지 평가해준다.
    + 단순회귀분석에서 하나의 계수가 유의미한가를 판단할 때 T검정을 쓴다.
    + 다중회귀분석에서 계수 하나하나가 유의미한가를 판단할 때 T검정을 쓴다.
    + 다중회귀분석에서 계수 하나하나를 판단할 필요 없이 모든 계수들이 유의미한가를 판단 할 때 F검정을 쓴다.
    
    + Types of Goodness of fit; 적합도검정의 종류들 
    
      1. F-test : 회귀식을 구성하는 모든 x variables이 useful한지 
        + F-test의 가정
          + H0 : ß1=ß2=ß3=...=ßn=0
            + x variables 중에서 단 한개도 y와 관련이 있지 않다.
          + Ha : At least one coefficient ßj ≠ 0
            + 적어도 하나의 x variable은 y와 관련이 있다. 
          + 만약 귀무가설이 reject되지 않는다면, correlation relationship을 바꿀 필요가 있다.
        + F-test는 적어도 하나의 x variable이 y의 예측에 관련이 있다는 것을 측정하는 것에 쓰일 수 있다.
        + [F-test(F검정)이란?](http://blog.naver.com/PostView.nhn?blogId=vnf3751&logNo=220841363022)
        
      2. T-test(Individual Test) : 어떤 x variable이 useful한지
        + F-test를 통해서 적어도 하나 이상의 x variable이 y 예측에 useful함을 알았다면, T-test를 통해서 개별 x variable를 검정한다. 
        + T-test의 가정
          + H0 : ß1 = 0
            + x1 has no effect on Y
          + Ha : ß1 ≠ 0
            + x1 has a significant effect on Y
            
      3. Coefficient of determination R2 : training poerformane 
        + 이것은 y의 변화에서 얼마나 많은 부분이 x에 의해 설명되어질 수 있는가를 측정할 수 있다.
        + 이것은 Training Data Set을 통해 predictive model이 얼마나 좋은가를 판단할 수 있다.
        + It is similar to "accuracy"
          + 오해 : **이것은 모델이 얼마나 좋은가를 판단하는 지표는 아니다!**
            이유 : 트레이닝세트에서 well performed되었다고 테스팅세트에서 잘된다는 보장은 없다. >> **overfitting problem.**
            그럼 어떻게 모델을 평가? : You have to use the test set to evaluate a model to tell how good it is.
        + R2
          + R2 = 1     : 100%의 x variable이 y를 설명한다. = x variables과 y와의 관계가 100% 선형적이다. 
          + 0 < R2 < 1 : Weaker linear relationships between x and y 
        + adj-R2 : 다른 x variables을 가진 두 개의 모델을 비교할 때 useful하다.
          + R2와는 다르게 y와 관계없는 x variable를 추가해도 증가하지 않는다.
          + 높은 adj-R2 값은 Training Data set을 통해 better model임을 나타낸다.
        + 보통 R2는 보지않고 adj-R2만 봤던거 같은데 아닌가? 
        
    + Overfitting Problem; 과적합 문제
      + 모델이 Training Data Set에 의하여 over-trained 된다면, Training Data Set에서는 high accuracy를 보일 수 있으나, Test Data Set에서는 bad performance를 보여준다.
      + Test Data Set의 정확도가 낮다고 해서 무조건 overfitting problem은 아니다.d
        + 아래 표를 본다면, 
          + accuracy1에서 training set > test set 이지만 차이가 별로 없으니 not overfitting
          + accuracy2에서 training set > test set 이지만 차이가 매우 크니 overfitting 
          
          ||training set|test set|
          |:---:|:---:|:---:|
          |accuracy1|95|92|
          |accuracy2|90|69| 
   
  + Residual Analysis; 잔차분석
    + 잔차값이 requirements를 만족하고, 모델에 문제가 있는지를 검증하기위해서 쓰인다.
    
    + The difference between error and residual
      + error: 모집단에서의 회귀식(y)의 값과 실제값(y)과의 차이
      + residual: 표본집단에서의 회귀식(y)의 값과 실제값(y)과의 차이
      + 분석에 있어서 우리는 모집단을 가지고 있는 경우가 없기 때문에, 모집단을 대표할 수 있는 표본집단을 이용하여 모집단의 회귀식을 추론하게 된다.
      + **결국, 오차와 잔차는 같은 개념이지만 모집단의 값인가, 표본의 값인가에 따라 서로 달리 부르게 되는 것이다.**
    
    + 회귀모델에 대한 가정
      + x와 y 사이의 관계는 선형적이다.
      + error
        1. 평균값 0을 가진다.
        2. 독립적이다.(True if sample is from simple random sampling)
        3. 일정한 분산, 표준편차를 가진다.
        4. 정규분포를 따른다. (Typically true for large samples)
      + 위의 가정들은 testing과 prediction을 위한 interential meothods를 끌어내는데 필요하다.
      + WARNING: **표본 크기가 30 이하**라면 residuals are not normal 할 것 이고, **회귀모델을 쓸 수 없다.**
    
    + Residual Analysis의 목표
      + 위의 회귀모델에 대한 가정을 참고했을 때
        1. x와 y가 선형적 관계임을 검증한다.
        2. ~~Zero mean~~
        3. ~~Independent~~
        4. 일정한 분산임을 검증한다.; 오차부분의 분포는 동일한 분산을 갖는다.
        5. 잔차가 정규분포임을 검증한다.
        6. (Optional) potential outliers를 확인한다.
      + 우리는 standardized residual for analysis를 사용하기에 2, 3는 검증할 필요가 없다. 
        + standardized residual : 잔차를 표준편차로 나누어 표준화한 값으로 outlier 판정의 기준이 됨.
    
    + Plots for 잔차분석
      1. Plot residual VS predicted value; 잔차 VS 예측값
        + 일정한 분산 확인
        + 분산이 일정하지 않다면?
          + you may need to y를 transformation하고 re-fit the regression model. 
      2. Plot residuals VS each x variable; 잔차 VS X
        + x와 y 사이의 선형성 확인
      3. Draw normal probability plot of residuals; 
        + residuals가 정규분포임을 확인하면 errors가 정규분포임을 확인할 수 있다. 
        + 점들이 라인에 근접하다면 errors는 approximately normal. Otherwise the assumption of normality is not satisfied.
        + Solution
          1. by QQPlot("Q" stands for quantile)
          2. Normality Test(For example, Shapiro-Wilk Normality Test)
            + H0 : variable(in this case, residuals) is normal distributed.
            + Ha : variable(in this case, residuals) is not normal distributed.
            + If p-value > 0.05, we say it follows normal distribution at 95% confidence level.
      4. Outlier identification
        + Possible outliers는 보통 (3 < error), (-3 > error)인 관찰값들이다. 
        + 위의 <br>**1. Plot residual VS predicted value**<br>**2.Plot residuals VS each x variable**<br>에서 outlier(large residuals)를 판별할 수 있다.
        
     + **Fitted Model**
      + 모델이 qualified or not 되었는지 어떻게 조사하지?
      + ** Steps **
      
        |Steps|MUST DO OR NOT|
        |:---:|:---:|
        |F-test|**MUST DO**|
        |Individual Parameter test|Optional|
        |Read Adj-R2|Optional|
        |Residual Analysis|**MUST DO**|
        |Outlier Detection|Optional|
      + 모델이 qualified 되었다면 model을 write down하고 evaluate the model on the test set.
      
        
        
  + Evaluations and Predictions; 모델 평가와 예측
    + 측정방법을 계산하고 **Testing Data Set**을 기초로 하여 모델을 평가한다.
    + Measuring predictive performance
      * 보통은 Adj-R2와 RMSE를 가지고 모델을 평가하는 듯..? Adj-R2가 높고, RMSE가 낮으면 좋은 모델!
      * Root Mean Square Error, RMSE 평균 제곱근 오차
        + Best model은 minimizes RMSE
      * Mean Absolute Error 평균 절대 오차
        + Best model은 minimizes MAE.
     

## Advanced Topics in Regression Models; 회귀모델에서의 토픽들
*Multicollinearity Problems; 다중공선성 문제*
  + x variable 간의 상관정도가 높아 부정적 영향을 끼치는 현상
  + What to do?
    + 상관정도가 높은 두 변수 중 하나를 제거해야함. 두 개 모두를 가지고 있을 필요가 없음.
  + 다중공산성이 있다는 것을 어떻게 평가함?
    * Pre-processing: 각 x variables 짝들의 Pearson correlation matrix와 scatter plots을 이용하여 조사함.<br>상관계수의 절대값이 0.9보다 크다면 serious 다중공선성 문제가 있다는 것임.
    * Post-processing: **모델을 먼저 만들고, VIF statistics를 이용**한다. **[Suggested!!!]**
      + VIF > 4이면, sign of strong multicollinearity이다.
      + 다중공선성이 있다면 두 개의 x variable 중 무엇을 지워야하는가?
        * It is based on my understand of data.<br>There is no fixed rules.<br>So if you think x1 is important than x2, you should remove x2
  + 왜 Pre-processing을 사용안함?
    * 우리는 높은 상관관계가 얼마나 큰 문제와 관계있는지 모름.
    * 우리는 어떤 variable를 제거해야 하는 지모름.
    * 몇몇 variable들은 모델을 만든 다음 없어지기도 함.
    
*Dummy Variable (When X is a qualitative varaible)*
  + **Dummy variable == Binary variable**
  + Binary variable의 경우에는 각각 0,1 을 붙여줘서 풀어주면 됨.<br>하지만 3개 이상이라면?
  + Dummy variable과의 상관관계는 해석하기 어렵다.
  + W7_01_20p~38p
  
*Higher-Order Multiple Linear Regression  고차 다중선형회귀*
  + Scatter plot를 보았을 때 이차방정식이나 삼차의 개형이 보이면 Line is not a good fit이다. 
  + 따라서 transformation of either x or Y to **"straighten out"** the curve 해야한다.<br>그럼에도불구하고 x와 y와의 관계가 이차 또는 삼차의 개형이라면 그것은 다항함수일 것 이다.
  + Polynomial regression; 다항회귀라면?
    1. Scatter plot의 개형을 보고 이차인지 삼차인지를 정한다.
    2. 그 다음에는 이러한 고차항을 표현할 수 있는 new varaibles를 생성한다.
    3. 다음 step은 linear regression model과 같다.
    4. Speical notes: 만약에 고차항을 추가할 것이라면,<br>lower-order terms should also be added to the model.<br>ex)3차항을 만든다면 2차, 1차항 또한 만들어야함.
  + *Interaction Terms*
    + **A special case of higher-order**
    + x1과 x2 사이에 상관관계가 있으면 x1×x2 항을 새로 만들어야함. 
    + 상관관계는 어떻게 알지?
      + 두 개 중 하나를 상수 5, 10, 15 이렇게 증가시켜봐서 3개의 그래프의 기울기가 변함없으면<br>No interaction. 기울기가 변한다면 Interaction.
      + ** 예 ** (a= x1, b= x2라고 하면)
      
        |value of b|No interactioned formula|interactioned formula|
        |:---:|:---:|:---:|
        |b|y=2a+3×b|y=2a+3×b+a×b|
        |5|y=2a+3×5|y=2a+3×5+a×5|
        |10|y=2a+3×10|y=2a+3×5+a×10|
        |15|y=2a+3×15|y=2a+3×5+a×15|
    + 종종 dummy variable들과 관련이 있다.
      + As association between the response variable Y and a predictor X varies for different levels of the dummy variable.
    + Interaction term을 관찰했다면, you shoud create a new variable to present this interaction term.
    + 그 다음 regular steps to build the model을 따르면 된다.
    + Interaction terms를 어떻게 해석할까?
      + x1과 x2가 모두 quantitative variable이라면 해석하기 어렵다.
      + 하지만 quantitative × dummy variable 이라면 해석하기 쉬워진다.<br>For example, Male and Female, they may have different impacts on the quantitative variable.
      
  *Influential Points 영향점*
 
  + 영향점이란, (typically)outlier들 중에서 fitted model에 영향을 미치는 점들이다.
  + Note: 모든 outlier가 영향점은 아니다.
  + 만약에 제거를 한다면 모델의 정확도를 향상시킬 수 있다.
  + Outlier들은 data & model에서 identified 될 수 있다.
    + From data: outlier detection (a data mining task)
    + From model: **residual analysis**
  + 하지만 Influential point들은 모델에서만 identified된다.
    + 그래서 모델을 먼저 만들고 제거해야한다. 
  + Matrics to Identify Influential Points
  
      |Fuctions|Description|Rough Cut-Off|
      |:---:|:---:|:---:|
      |diffits()|||
      |dfbetas()|||
      |covratio()|||
      |hatvalues()|||
      |cooks.distance()|회귀 직선의 모양(기울기나 절편 등)에 크게 영향을 끼치는 점들을 찾는 그래프standardized distance change for how far the estimated vector|cook.d > 4/n|
      
      + cooks.distance를 예로 들자면, cook.d가 4/n보다 크다면 제거해야한다.
      + 하지만 데이터가 small하다면 모든 influential point를 제거할 수 없으므로 largest one부터 데이터크기에 비례하여 지운다.
      + [Influential Point + R 코딩에 참고될만한 링크](https://datascienceschool.net/view-notebook/6d9c833f132e4e789e35632b49be2c2d/)
    

      
## Important Notes
> 만약에 y variable에 transformation을 적용했다면,<br>만들어낸 the predicted value는<br>based on transformed y variable일 것 이다.<br>따라서 마지막에는 convert it back to the original unit 해야한다.
> For exmaple, log(y) = 6 + 2x이면, To get predicted y values,<br>you should use exp() function to be applied on the predicted log(y).
